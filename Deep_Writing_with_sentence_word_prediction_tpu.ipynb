{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Deep_Writing_with_sentence_word_prediction_tpu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumarneeraj2005/2048-Deep-Learning/blob/master/Deep_Writing_with_sentence_word_prediction_tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUb856aHtNq_",
        "colab_type": "code",
        "outputId": "475dd9e8-ad30-4a37-e35c-9853c0d132cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import regex as re\n",
        "\n",
        "import nltk\n",
        "from nltk.draw.dispersion import dispersion_plot\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.probability import FreqDist\n",
        "from textblob import TextBlob\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.util import ngrams\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Embedding\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import urllib\n",
        "\n",
        "import os\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3MnaG43tZeA",
        "colab_type": "code",
        "outputId": "dfb5e2a8-dfc5-4743-ef86-e4122f288a1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text = urllib.request.urlopen('http://www.textfiles.com/stories/3gables.txt').read().decode('utf8')\n",
        "text = text.replace('\\n', ' ').replace('\\r', '').replace(\"\\'\", \"\").replace('\\w+', '')[348:500]\n",
        "text[0:1000]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'   I dont think that any of my adventures with Mr. Sherlock Holmes opened quite so abruptly, or so dramatically, as that which I associate with The Thre'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS16E8LAtfBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I will first convert all the words to numbers, then normalize them, then make a dataframe with two columns, \n",
        "# one with sentences(one word, then two words, and so on), the other with the exact next word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnHkDWF6uB-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# integer encode text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "encoded = tokenizer.texts_to_sequences([text])[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntGz5c9lukSF",
        "colab_type": "code",
        "outputId": "b6783160-167f-4fbc-e833-7c3c93e16db1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# determine the vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olhiAHoo5Q26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x = pd.DataFrame(pd.Series([encoded[:i] for i in range(len(encoded))]))\n",
        "# x['label'] = pd.DataFrame([i for i in encoded])\n",
        "# x.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa77eQj05bpI",
        "colab_type": "code",
        "outputId": "dba4bf2e-2cb2-4680-e72b-15c19fa8d470",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "listy = []\n",
        "\n",
        "for i in range(len(encoded)):\n",
        "  listy.append(encoded[:i])\n",
        "  \n",
        "len(listy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO15yM1vdofW",
        "colab_type": "code",
        "outputId": "dd10aca0-5eb4-4f90-c77a-53fd11cac0f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "listy[1:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1],\n",
              " [1, 5],\n",
              " [1, 5, 6],\n",
              " [1, 5, 6, 2],\n",
              " [1, 5, 6, 2, 7],\n",
              " [1, 5, 6, 2, 7, 8],\n",
              " [1, 5, 6, 2, 7, 8, 9],\n",
              " [1, 5, 6, 2, 7, 8, 9, 10],\n",
              " [1, 5, 6, 2, 7, 8, 9, 10, 3]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHAmZBhhYFzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.array([np.array(xi) for xi in listy[1:]]) # creating array retaining the shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH0pUQEJZuNw",
        "colab_type": "code",
        "outputId": "afdfaf82-74ed-4744-e73c-089f13d13742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "length = len(sorted(listy[1:],key = len, reverse = True)[0])   # creating array by adding 0 to make all rows equal\n",
        "X = np.array([xi + [0] * (length - len(xi)) for xi in listy[1:]])\n",
        "X.shape  # creating X array"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26, 26)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOpL0qlCsVff",
        "colab_type": "code",
        "outputId": "6e40b717-22ce-45f1-e497-3209d9962e6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
            "  warnings.warn(msg, DataConversionWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
            "  warnings.warn(msg, DataConversionWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaIZP8UtX0J9",
        "colab_type": "code",
        "outputId": "90119835-5337-4d66-b2bf-d31ec4358b15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "X[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.        , -5.        , -3.46410162, -2.76887462, -2.34520788,\n",
              "       -2.04939015, -1.82574186, -1.64750894, -1.5       , -1.37436854,\n",
              "       -1.26491106, -1.16774842, -1.08012345, -1.        , -0.9258201 ,\n",
              "       -0.85634884, -0.79056942, -0.72760688, -0.66666667, -0.60697698,\n",
              "       -0.54772256, -0.48795004, -0.42640143, -0.36115756, -0.28867513,\n",
              "       -0.2       ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMq9FIMbN7tq",
        "colab_type": "code",
        "outputId": "7278d81a-1fe6-4d12-c522-1650b9a531aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = [i for i in encoded][1:] # creating y array\n",
        "len(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBtV_MblN_ly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encode outputs\n",
        "y = to_categorical(y, num_classes = vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8hS0EsOsHZK",
        "colab_type": "code",
        "outputId": "08b3a4cd-9e74-4c0d-cf1b-3896575b7ff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh72jiM3LZkH",
        "colab_type": "code",
        "outputId": "753a3659-5384-45bb-bfa0-77d8887c4616",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((26, 26), (26, 24))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT6XGFybeuRM",
        "colab_type": "code",
        "outputId": "b1929632-5599-4f9a-b335-ec40b0bb65ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# LSTMs accept input in the form of (number_of_sequences, length_of_sequence, number_of_features)\n",
        "X_lstm = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "X_lstm.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26, 26, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiS7DGsZfg4A",
        "colab_type": "code",
        "outputId": "bc6d91ab-273d-4e78-a64a-5ad2fd0fa18a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.LSTM(50, input_shape = (X_lstm.shape[1], X_lstm.shape[2])))#, return_sequences = True))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "# model.add(tf.keras.layers.LSTM(50, return_sequences = True))\n",
        "# model.add(tf.keras.layers.Dropout(0.2))\n",
        "# model.add(tf.keras.layers.LSTM(500, return_sequences = True))\n",
        "# model.add(tf.keras.layers.Dropout(0.2))\n",
        "# model.add(tf.keras.layers.LSTM(500, return_sequences = True))\n",
        "# model.add(tf.keras.layers.Dropout(0.2))\n",
        "# model.add(tf.keras.layers.LSTM(2500, return_sequences = True))\n",
        "# model.add(tf.keras.layers.Dropout(0.2))\n",
        "# model.add(tf.keras.layers.LSTM(50))\n",
        "# model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 50)                10400     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 24)                1224      \n",
            "=================================================================\n",
            "Total params: 11,624\n",
            "Trainable params: 11,624\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDd_BheDe5jb",
        "colab_type": "code",
        "outputId": "dc2c8ba9-f973-42cd-9528-7db0adc69fe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.86.123.98:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 9908395419379460952)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 11439517981440160975)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 1212404706152780327)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 12049659652082386877)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 1966401837543455855)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 4490064321698689561)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 13793037818812237758)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 8847118372390118553)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 15764082774091686476)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 3198362694413858952)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 11516689499842027663)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54bVMlFbfAJU",
        "colab_type": "code",
        "outputId": "8efab62e-3e30-4fa1-b7b7-4952351ff5d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "tpu_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_input (InputLayer)      (None, 26, 1)             0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50)                10400     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 24)                1224      \n",
            "=================================================================\n",
            "Total params: 11,624\n",
            "Trainable params: 11,624\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnaZY1IrfEso",
        "colab_type": "code",
        "outputId": "2a52878b-1056-4f04-e44f-89e95a6347cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17394
        }
      },
      "source": [
        "#early_stopping_monitor = EarlyStopping(monitor = 'loss', patience = 4, verbose = 0, mode='auto')\n",
        "tpu_model.fit(X_lstm, y, epochs = 500, batch_size = 50)#, callbacks = [early_stopping_monitor])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(3,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(3, 26, 1), dtype=tf.float32, name='lstm_input_10'), TensorSpec(shape=(3, 24), dtype=tf.float32, name='dense_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "INFO:tensorflow:Remapping placeholder for lstm_input\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7fa3d1df2898> []\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 2.108351707458496 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "INFO:tensorflow:CPU -> TPU lr: 0.0010000000474974513 {0.001}\n",
            "INFO:tensorflow:CPU -> TPU beta_1: 0.8999999761581421 {0.9}\n",
            "INFO:tensorflow:CPU -> TPU beta_2: 0.9990000128746033 {0.999}\n",
            "INFO:tensorflow:CPU -> TPU decay: 0.0 {0.0}\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "26/26 [==============================] - 11s 420ms/sample - loss: 3.1843 - acc: 0.0417\n",
            "Epoch 2/500\n",
            "26/26 [==============================] - 0s 740us/sample - loss: 3.1804 - acc: 0.0000e+00\n",
            "Epoch 3/500\n",
            "26/26 [==============================] - 0s 665us/sample - loss: 3.1809 - acc: 0.0417\n",
            "Epoch 4/500\n",
            "26/26 [==============================] - 0s 504us/sample - loss: 3.1775 - acc: 0.1250\n",
            "Epoch 5/500\n",
            "26/26 [==============================] - 0s 579us/sample - loss: 3.1650 - acc: 0.0417\n",
            "Epoch 6/500\n",
            "26/26 [==============================] - 0s 590us/sample - loss: 3.1605 - acc: 0.2083\n",
            "Epoch 7/500\n",
            "26/26 [==============================] - 0s 508us/sample - loss: 3.1611 - acc: 0.0417\n",
            "Epoch 8/500\n",
            "26/26 [==============================] - 0s 535us/sample - loss: 3.1547 - acc: 0.1667\n",
            "Epoch 9/500\n",
            "26/26 [==============================] - 0s 660us/sample - loss: 3.1494 - acc: 0.0417\n",
            "Epoch 10/500\n",
            "26/26 [==============================] - 0s 479us/sample - loss: 3.1343 - acc: 0.2083\n",
            "Epoch 11/500\n",
            "26/26 [==============================] - 0s 544us/sample - loss: 3.1441 - acc: 0.1250\n",
            "Epoch 12/500\n",
            "26/26 [==============================] - 0s 558us/sample - loss: 3.1178 - acc: 0.1250\n",
            "Epoch 13/500\n",
            "26/26 [==============================] - 0s 568us/sample - loss: 3.1214 - acc: 0.0833\n",
            "Epoch 14/500\n",
            "26/26 [==============================] - 0s 577us/sample - loss: 3.1067 - acc: 0.1250\n",
            "Epoch 15/500\n",
            "26/26 [==============================] - 0s 540us/sample - loss: 3.1235 - acc: 0.1667\n",
            "Epoch 16/500\n",
            "26/26 [==============================] - 0s 553us/sample - loss: 3.0961 - acc: 0.0833\n",
            "Epoch 17/500\n",
            "26/26 [==============================] - 0s 628us/sample - loss: 3.1202 - acc: 0.1667\n",
            "Epoch 18/500\n",
            "26/26 [==============================] - 0s 590us/sample - loss: 3.1201 - acc: 0.1250\n",
            "Epoch 19/500\n",
            "26/26 [==============================] - 0s 546us/sample - loss: 3.1024 - acc: 0.1250\n",
            "Epoch 20/500\n",
            "26/26 [==============================] - 0s 860us/sample - loss: 3.0749 - acc: 0.1250\n",
            "Epoch 21/500\n",
            "26/26 [==============================] - 0s 783us/sample - loss: 3.0617 - acc: 0.0833\n",
            "Epoch 22/500\n",
            "26/26 [==============================] - 0s 673us/sample - loss: 3.0541 - acc: 0.0833\n",
            "Epoch 23/500\n",
            "26/26 [==============================] - 0s 660us/sample - loss: 3.0314 - acc: 0.1250\n",
            "Epoch 24/500\n",
            "26/26 [==============================] - 0s 677us/sample - loss: 3.0195 - acc: 0.1250\n",
            "Epoch 25/500\n",
            "26/26 [==============================] - 0s 544us/sample - loss: 3.0006 - acc: 0.1667\n",
            "Epoch 26/500\n",
            "26/26 [==============================] - 0s 559us/sample - loss: 3.0001 - acc: 0.0833\n",
            "Epoch 27/500\n",
            "26/26 [==============================] - 0s 572us/sample - loss: 2.9824 - acc: 0.0833\n",
            "Epoch 28/500\n",
            "26/26 [==============================] - 0s 531us/sample - loss: 2.9963 - acc: 0.1667\n",
            "Epoch 29/500\n",
            "26/26 [==============================] - 0s 547us/sample - loss: 2.9430 - acc: 0.2083\n",
            "Epoch 30/500\n",
            "26/26 [==============================] - 0s 601us/sample - loss: 2.9335 - acc: 0.1667\n",
            "Epoch 31/500\n",
            "26/26 [==============================] - 0s 467us/sample - loss: 2.9040 - acc: 0.0417\n",
            "Epoch 32/500\n",
            "26/26 [==============================] - 0s 521us/sample - loss: 2.9221 - acc: 0.0833\n",
            "Epoch 33/500\n",
            "26/26 [==============================] - 0s 642us/sample - loss: 2.9547 - acc: 0.0417\n",
            "Epoch 34/500\n",
            "26/26 [==============================] - 0s 679us/sample - loss: 2.8208 - acc: 0.0833\n",
            "Epoch 35/500\n",
            "26/26 [==============================] - 0s 705us/sample - loss: 2.8743 - acc: 0.1667\n",
            "Epoch 36/500\n",
            "26/26 [==============================] - 0s 502us/sample - loss: 2.8784 - acc: 0.1667\n",
            "Epoch 37/500\n",
            "26/26 [==============================] - 0s 577us/sample - loss: 2.8752 - acc: 0.1250\n",
            "Epoch 38/500\n",
            "26/26 [==============================] - 0s 511us/sample - loss: 2.8663 - acc: 0.0417\n",
            "Epoch 39/500\n",
            "26/26 [==============================] - 0s 609us/sample - loss: 2.7211 - acc: 0.1250\n",
            "Epoch 40/500\n",
            "26/26 [==============================] - 0s 565us/sample - loss: 2.8013 - acc: 0.1250\n",
            "Epoch 41/500\n",
            "26/26 [==============================] - 0s 589us/sample - loss: 2.7591 - acc: 0.2083\n",
            "Epoch 42/500\n",
            "26/26 [==============================] - 0s 566us/sample - loss: 2.7312 - acc: 0.1667\n",
            "Epoch 43/500\n",
            "26/26 [==============================] - 0s 525us/sample - loss: 2.7473 - acc: 0.1667\n",
            "Epoch 44/500\n",
            "26/26 [==============================] - 0s 521us/sample - loss: 2.8373 - acc: 0.1250\n",
            "Epoch 45/500\n",
            "26/26 [==============================] - 0s 579us/sample - loss: 2.7501 - acc: 0.1250\n",
            "Epoch 46/500\n",
            "26/26 [==============================] - 0s 551us/sample - loss: 2.7467 - acc: 0.1250\n",
            "Epoch 47/500\n",
            "26/26 [==============================] - 0s 789us/sample - loss: 2.5967 - acc: 0.3333\n",
            "Epoch 48/500\n",
            "26/26 [==============================] - 0s 570us/sample - loss: 2.6642 - acc: 0.1667\n",
            "Epoch 49/500\n",
            "26/26 [==============================] - 0s 546us/sample - loss: 2.7202 - acc: 0.1250\n",
            "Epoch 50/500\n",
            "26/26 [==============================] - 0s 832us/sample - loss: 2.6588 - acc: 0.1667\n",
            "Epoch 51/500\n",
            "26/26 [==============================] - 0s 588us/sample - loss: 2.5409 - acc: 0.2500\n",
            "Epoch 52/500\n",
            "26/26 [==============================] - 0s 605us/sample - loss: 2.5835 - acc: 0.1250\n",
            "Epoch 53/500\n",
            "26/26 [==============================] - 0s 620us/sample - loss: 2.5952 - acc: 0.2083\n",
            "Epoch 54/500\n",
            "26/26 [==============================] - 0s 624us/sample - loss: 2.5976 - acc: 0.3750\n",
            "Epoch 55/500\n",
            "26/26 [==============================] - 0s 546us/sample - loss: 2.5430 - acc: 0.1667\n",
            "Epoch 56/500\n",
            "26/26 [==============================] - 0s 557us/sample - loss: 2.5613 - acc: 0.2500\n",
            "Epoch 57/500\n",
            "26/26 [==============================] - 0s 514us/sample - loss: 2.4317 - acc: 0.2083\n",
            "Epoch 58/500\n",
            "26/26 [==============================] - 0s 516us/sample - loss: 2.4605 - acc: 0.1250\n",
            "Epoch 59/500\n",
            "26/26 [==============================] - 0s 590us/sample - loss: 2.5071 - acc: 0.2500\n",
            "Epoch 60/500\n",
            "26/26 [==============================] - 0s 581us/sample - loss: 2.3994 - acc: 0.2083\n",
            "Epoch 61/500\n",
            "26/26 [==============================] - 0s 661us/sample - loss: 2.5077 - acc: 0.2500\n",
            "Epoch 62/500\n",
            "26/26 [==============================] - 0s 578us/sample - loss: 2.5003 - acc: 0.1667\n",
            "Epoch 63/500\n",
            "26/26 [==============================] - 0s 628us/sample - loss: 2.4726 - acc: 0.2917\n",
            "Epoch 64/500\n",
            "26/26 [==============================] - 0s 587us/sample - loss: 2.4931 - acc: 0.3333\n",
            "Epoch 65/500\n",
            "26/26 [==============================] - 0s 559us/sample - loss: 2.2808 - acc: 0.3333\n",
            "Epoch 66/500\n",
            "26/26 [==============================] - 0s 598us/sample - loss: 2.3996 - acc: 0.2083\n",
            "Epoch 67/500\n",
            "26/26 [==============================] - 0s 619us/sample - loss: 2.3940 - acc: 0.2083\n",
            "Epoch 68/500\n",
            "26/26 [==============================] - 0s 582us/sample - loss: 2.3655 - acc: 0.2500\n",
            "Epoch 69/500\n",
            "26/26 [==============================] - 0s 551us/sample - loss: 2.4353 - acc: 0.2083\n",
            "Epoch 70/500\n",
            "26/26 [==============================] - 0s 530us/sample - loss: 2.3113 - acc: 0.2083\n",
            "Epoch 71/500\n",
            "26/26 [==============================] - 0s 677us/sample - loss: 2.2567 - acc: 0.1667\n",
            "Epoch 72/500\n",
            "26/26 [==============================] - 0s 729us/sample - loss: 2.3679 - acc: 0.2500\n",
            "Epoch 73/500\n",
            "26/26 [==============================] - 0s 551us/sample - loss: 2.3430 - acc: 0.2083\n",
            "Epoch 74/500\n",
            "26/26 [==============================] - 0s 562us/sample - loss: 2.2182 - acc: 0.2917\n",
            "Epoch 75/500\n",
            "26/26 [==============================] - 0s 505us/sample - loss: 2.2453 - acc: 0.2917\n",
            "Epoch 76/500\n",
            "26/26 [==============================] - 0s 516us/sample - loss: 2.2454 - acc: 0.3750\n",
            "Epoch 77/500\n",
            "26/26 [==============================] - 0s 592us/sample - loss: 2.2894 - acc: 0.2083\n",
            "Epoch 78/500\n",
            "26/26 [==============================] - 0s 543us/sample - loss: 2.2649 - acc: 0.2500\n",
            "Epoch 79/500\n",
            "26/26 [==============================] - 0s 648us/sample - loss: 2.2573 - acc: 0.4167\n",
            "Epoch 80/500\n",
            "26/26 [==============================] - 0s 483us/sample - loss: 2.2720 - acc: 0.2917\n",
            "Epoch 81/500\n",
            "26/26 [==============================] - 0s 909us/sample - loss: 2.2222 - acc: 0.2917\n",
            "Epoch 82/500\n",
            "26/26 [==============================] - 0s 537us/sample - loss: 2.1724 - acc: 0.2917\n",
            "Epoch 83/500\n",
            "26/26 [==============================] - 0s 494us/sample - loss: 2.2487 - acc: 0.2917\n",
            "Epoch 84/500\n",
            "26/26 [==============================] - 0s 553us/sample - loss: 2.2055 - acc: 0.2083\n",
            "Epoch 85/500\n",
            "26/26 [==============================] - 0s 550us/sample - loss: 2.2153 - acc: 0.2500\n",
            "Epoch 86/500\n",
            "26/26 [==============================] - 0s 498us/sample - loss: 2.1707 - acc: 0.2917\n",
            "Epoch 87/500\n",
            "26/26 [==============================] - 0s 670us/sample - loss: 2.1517 - acc: 0.2917\n",
            "Epoch 88/500\n",
            "26/26 [==============================] - 0s 618us/sample - loss: 2.1976 - acc: 0.2500\n",
            "Epoch 89/500\n",
            "26/26 [==============================] - 0s 519us/sample - loss: 2.1554 - acc: 0.2917\n",
            "Epoch 90/500\n",
            "26/26 [==============================] - 0s 893us/sample - loss: 2.1304 - acc: 0.3333\n",
            "Epoch 91/500\n",
            "26/26 [==============================] - 0s 562us/sample - loss: 2.1004 - acc: 0.3333\n",
            "Epoch 92/500\n",
            "26/26 [==============================] - 0s 707us/sample - loss: 2.0082 - acc: 0.3750\n",
            "Epoch 93/500\n",
            "26/26 [==============================] - 0s 486us/sample - loss: 2.1866 - acc: 0.2083\n",
            "Epoch 94/500\n",
            "26/26 [==============================] - 0s 509us/sample - loss: 2.1033 - acc: 0.2917\n",
            "Epoch 95/500\n",
            "26/26 [==============================] - 0s 526us/sample - loss: 2.0111 - acc: 0.3750\n",
            "Epoch 96/500\n",
            "26/26 [==============================] - 0s 500us/sample - loss: 2.1187 - acc: 0.2917\n",
            "Epoch 97/500\n",
            "26/26 [==============================] - 0s 609us/sample - loss: 2.0309 - acc: 0.5000\n",
            "Epoch 98/500\n",
            "26/26 [==============================] - 0s 480us/sample - loss: 2.0509 - acc: 0.2500\n",
            "Epoch 99/500\n",
            "26/26 [==============================] - 0s 559us/sample - loss: 2.0448 - acc: 0.2500\n",
            "Epoch 100/500\n",
            "26/26 [==============================] - 0s 617us/sample - loss: 2.0754 - acc: 0.2500\n",
            "Epoch 101/500\n",
            "26/26 [==============================] - 0s 491us/sample - loss: 2.0620 - acc: 0.3333\n",
            "Epoch 102/500\n",
            "26/26 [==============================] - 0s 506us/sample - loss: 2.0736 - acc: 0.4167\n",
            "Epoch 103/500\n",
            "26/26 [==============================] - 0s 479us/sample - loss: 2.1180 - acc: 0.2500\n",
            "Epoch 104/500\n",
            "26/26 [==============================] - 0s 595us/sample - loss: 2.0339 - acc: 0.3333\n",
            "Epoch 105/500\n",
            "26/26 [==============================] - 0s 645us/sample - loss: 2.0757 - acc: 0.2500\n",
            "Epoch 106/500\n",
            "26/26 [==============================] - 0s 860us/sample - loss: 2.0315 - acc: 0.2500\n",
            "Epoch 107/500\n",
            "26/26 [==============================] - 0s 669us/sample - loss: 1.9709 - acc: 0.4167\n",
            "Epoch 108/500\n",
            "26/26 [==============================] - 0s 645us/sample - loss: 1.9116 - acc: 0.4583\n",
            "Epoch 109/500\n",
            "26/26 [==============================] - 0s 661us/sample - loss: 1.9813 - acc: 0.2083\n",
            "Epoch 110/500\n",
            "26/26 [==============================] - 0s 528us/sample - loss: 1.9456 - acc: 0.3333\n",
            "Epoch 111/500\n",
            "26/26 [==============================] - 0s 502us/sample - loss: 1.8623 - acc: 0.4583\n",
            "Epoch 112/500\n",
            "26/26 [==============================] - 0s 500us/sample - loss: 1.9369 - acc: 0.2917\n",
            "Epoch 113/500\n",
            "26/26 [==============================] - 0s 465us/sample - loss: 1.9583 - acc: 0.2917\n",
            "Epoch 114/500\n",
            "26/26 [==============================] - 0s 521us/sample - loss: 1.9477 - acc: 0.3750\n",
            "Epoch 115/500\n",
            "26/26 [==============================] - 0s 526us/sample - loss: 1.9080 - acc: 0.3333\n",
            "Epoch 116/500\n",
            "26/26 [==============================] - 0s 472us/sample - loss: 1.7663 - acc: 0.5000\n",
            "Epoch 117/500\n",
            "26/26 [==============================] - 0s 561us/sample - loss: 1.8055 - acc: 0.5000\n",
            "Epoch 118/500\n",
            "26/26 [==============================] - 0s 676us/sample - loss: 1.8669 - acc: 0.4583\n",
            "Epoch 119/500\n",
            "26/26 [==============================] - 0s 570us/sample - loss: 1.9123 - acc: 0.2917\n",
            "Epoch 120/500\n",
            "26/26 [==============================] - 0s 552us/sample - loss: 1.9049 - acc: 0.3750\n",
            "Epoch 121/500\n",
            "26/26 [==============================] - 0s 563us/sample - loss: 1.7513 - acc: 0.4583\n",
            "Epoch 122/500\n",
            "26/26 [==============================] - 0s 459us/sample - loss: 1.7671 - acc: 0.5000\n",
            "Epoch 123/500\n",
            "26/26 [==============================] - 0s 615us/sample - loss: 1.9417 - acc: 0.3333\n",
            "Epoch 124/500\n",
            "26/26 [==============================] - 0s 567us/sample - loss: 1.9134 - acc: 0.2917\n",
            "Epoch 125/500\n",
            "26/26 [==============================] - 0s 551us/sample - loss: 1.8442 - acc: 0.3333\n",
            "Epoch 126/500\n",
            "26/26 [==============================] - 0s 541us/sample - loss: 1.8242 - acc: 0.4167\n",
            "Epoch 127/500\n",
            "26/26 [==============================] - 0s 520us/sample - loss: 1.7399 - acc: 0.4167\n",
            "Epoch 128/500\n",
            "26/26 [==============================] - 0s 478us/sample - loss: 1.8582 - acc: 0.2500\n",
            "Epoch 129/500\n",
            "26/26 [==============================] - 0s 481us/sample - loss: 1.7760 - acc: 0.4583\n",
            "Epoch 130/500\n",
            "26/26 [==============================] - 0s 471us/sample - loss: 1.7593 - acc: 0.5000\n",
            "Epoch 131/500\n",
            "26/26 [==============================] - 0s 570us/sample - loss: 1.6494 - acc: 0.5417\n",
            "Epoch 132/500\n",
            "26/26 [==============================] - 0s 490us/sample - loss: 1.7164 - acc: 0.5000\n",
            "Epoch 133/500\n",
            "26/26 [==============================] - 0s 536us/sample - loss: 1.6925 - acc: 0.4167\n",
            "Epoch 134/500\n",
            "26/26 [==============================] - 0s 494us/sample - loss: 1.7843 - acc: 0.3750\n",
            "Epoch 135/500\n",
            "26/26 [==============================] - 0s 451us/sample - loss: 1.7458 - acc: 0.3750\n",
            "Epoch 136/500\n",
            "26/26 [==============================] - 0s 569us/sample - loss: 1.7138 - acc: 0.4167\n",
            "Epoch 137/500\n",
            "26/26 [==============================] - 0s 608us/sample - loss: 1.7598 - acc: 0.4583\n",
            "Epoch 138/500\n",
            "26/26 [==============================] - 0s 464us/sample - loss: 1.7312 - acc: 0.4583\n",
            "Epoch 139/500\n",
            "26/26 [==============================] - 0s 544us/sample - loss: 1.7120 - acc: 0.3333\n",
            "Epoch 140/500\n",
            "26/26 [==============================] - 0s 585us/sample - loss: 1.6698 - acc: 0.4167\n",
            "Epoch 141/500\n",
            "26/26 [==============================] - 0s 562us/sample - loss: 1.6825 - acc: 0.4167\n",
            "Epoch 142/500\n",
            "26/26 [==============================] - 0s 541us/sample - loss: 1.6755 - acc: 0.4167\n",
            "Epoch 143/500\n",
            "26/26 [==============================] - 0s 486us/sample - loss: 1.6741 - acc: 0.3333\n",
            "Epoch 144/500\n",
            "26/26 [==============================] - 0s 481us/sample - loss: 1.6634 - acc: 0.5000\n",
            "Epoch 145/500\n",
            "26/26 [==============================] - 0s 447us/sample - loss: 1.6485 - acc: 0.4167\n",
            "Epoch 146/500\n",
            "26/26 [==============================] - 0s 556us/sample - loss: 1.5597 - acc: 0.5833\n",
            "Epoch 147/500\n",
            "26/26 [==============================] - 0s 503us/sample - loss: 1.6708 - acc: 0.4583\n",
            "Epoch 148/500\n",
            "26/26 [==============================] - 0s 608us/sample - loss: 1.6360 - acc: 0.4167\n",
            "Epoch 149/500\n",
            "26/26 [==============================] - 0s 515us/sample - loss: 1.6074 - acc: 0.5000\n",
            "Epoch 150/500\n",
            "26/26 [==============================] - 0s 604us/sample - loss: 1.6498 - acc: 0.4167\n",
            "Epoch 151/500\n",
            "26/26 [==============================] - 0s 461us/sample - loss: 1.5830 - acc: 0.5417\n",
            "Epoch 152/500\n",
            "26/26 [==============================] - 0s 513us/sample - loss: 1.5923 - acc: 0.6250\n",
            "Epoch 153/500\n",
            "26/26 [==============================] - 0s 531us/sample - loss: 1.6243 - acc: 0.4583\n",
            "Epoch 154/500\n",
            "26/26 [==============================] - 0s 505us/sample - loss: 1.5578 - acc: 0.5000\n",
            "Epoch 155/500\n",
            "26/26 [==============================] - 0s 638us/sample - loss: 1.5708 - acc: 0.5000\n",
            "Epoch 156/500\n",
            "26/26 [==============================] - 0s 478us/sample - loss: 1.5886 - acc: 0.3750\n",
            "Epoch 157/500\n",
            "26/26 [==============================] - 0s 740us/sample - loss: 1.5562 - acc: 0.5000\n",
            "Epoch 158/500\n",
            "26/26 [==============================] - 0s 512us/sample - loss: 1.5895 - acc: 0.4583\n",
            "Epoch 159/500\n",
            "26/26 [==============================] - 0s 519us/sample - loss: 1.5373 - acc: 0.4167\n",
            "Epoch 160/500\n",
            "26/26 [==============================] - 0s 540us/sample - loss: 1.5706 - acc: 0.5417\n",
            "Epoch 161/500\n",
            "26/26 [==============================] - 0s 568us/sample - loss: 1.6297 - acc: 0.4583\n",
            "Epoch 162/500\n",
            "26/26 [==============================] - 0s 653us/sample - loss: 1.4574 - acc: 0.6250\n",
            "Epoch 163/500\n",
            "26/26 [==============================] - 0s 656us/sample - loss: 1.5850 - acc: 0.5833\n",
            "Epoch 164/500\n",
            "26/26 [==============================] - 0s 502us/sample - loss: 1.6197 - acc: 0.4583\n",
            "Epoch 165/500\n",
            "26/26 [==============================] - 0s 692us/sample - loss: 1.6491 - acc: 0.4167\n",
            "Epoch 166/500\n",
            "26/26 [==============================] - 0s 484us/sample - loss: 1.6585 - acc: 0.4167\n",
            "Epoch 167/500\n",
            "26/26 [==============================] - 0s 629us/sample - loss: 1.5382 - acc: 0.5417\n",
            "Epoch 168/500\n",
            "26/26 [==============================] - 0s 531us/sample - loss: 1.5175 - acc: 0.4167\n",
            "Epoch 169/500\n",
            "26/26 [==============================] - 0s 599us/sample - loss: 1.5911 - acc: 0.4583\n",
            "Epoch 170/500\n",
            "26/26 [==============================] - 0s 583us/sample - loss: 1.4633 - acc: 0.7500\n",
            "Epoch 171/500\n",
            "26/26 [==============================] - 0s 555us/sample - loss: 1.6828 - acc: 0.4583\n",
            "Epoch 172/500\n",
            "26/26 [==============================] - 0s 555us/sample - loss: 1.5080 - acc: 0.5417\n",
            "Epoch 173/500\n",
            "26/26 [==============================] - 0s 586us/sample - loss: 1.4665 - acc: 0.5000\n",
            "Epoch 174/500\n",
            "26/26 [==============================] - 0s 769us/sample - loss: 1.5805 - acc: 0.3750\n",
            "Epoch 175/500\n",
            "26/26 [==============================] - 0s 572us/sample - loss: 1.4425 - acc: 0.6667\n",
            "Epoch 176/500\n",
            "26/26 [==============================] - 0s 506us/sample - loss: 1.4878 - acc: 0.5417\n",
            "Epoch 177/500\n",
            "26/26 [==============================] - 0s 678us/sample - loss: 1.3760 - acc: 0.5000\n",
            "Epoch 178/500\n",
            "26/26 [==============================] - 0s 512us/sample - loss: 1.6007 - acc: 0.4167\n",
            "Epoch 179/500\n",
            "26/26 [==============================] - 0s 531us/sample - loss: 1.5475 - acc: 0.4583\n",
            "Epoch 180/500\n",
            "26/26 [==============================] - 0s 527us/sample - loss: 1.4870 - acc: 0.4167\n",
            "Epoch 181/500\n",
            "26/26 [==============================] - 0s 555us/sample - loss: 1.4163 - acc: 0.5833\n",
            "Epoch 182/500\n",
            "26/26 [==============================] - 0s 501us/sample - loss: 1.3794 - acc: 0.7500\n",
            "Epoch 183/500\n",
            "26/26 [==============================] - 0s 509us/sample - loss: 1.4311 - acc: 0.5000\n",
            "Epoch 184/500\n",
            "26/26 [==============================] - 0s 1ms/sample - loss: 1.3790 - acc: 0.7083\n",
            "Epoch 185/500\n",
            "26/26 [==============================] - 0s 509us/sample - loss: 1.3743 - acc: 0.5833\n",
            "Epoch 186/500\n",
            "26/26 [==============================] - 0s 476us/sample - loss: 1.4053 - acc: 0.4583\n",
            "Epoch 187/500\n",
            "26/26 [==============================] - 0s 433us/sample - loss: 1.4288 - acc: 0.5417\n",
            "Epoch 188/500\n",
            "26/26 [==============================] - 0s 642us/sample - loss: 1.3332 - acc: 0.7083\n",
            "Epoch 189/500\n",
            "26/26 [==============================] - 0s 488us/sample - loss: 1.4102 - acc: 0.6250\n",
            "Epoch 190/500\n",
            "26/26 [==============================] - 0s 522us/sample - loss: 1.4259 - acc: 0.4583\n",
            "Epoch 191/500\n",
            "26/26 [==============================] - 0s 457us/sample - loss: 1.4389 - acc: 0.5417\n",
            "Epoch 192/500\n",
            "26/26 [==============================] - 0s 552us/sample - loss: 1.3403 - acc: 0.6667\n",
            "Epoch 193/500\n",
            "26/26 [==============================] - 0s 508us/sample - loss: 1.3400 - acc: 0.6250\n",
            "Epoch 194/500\n",
            "26/26 [==============================] - 0s 453us/sample - loss: 1.2822 - acc: 0.6667\n",
            "Epoch 195/500\n",
            "26/26 [==============================] - 0s 526us/sample - loss: 1.4127 - acc: 0.5000\n",
            "Epoch 196/500\n",
            "26/26 [==============================] - 0s 502us/sample - loss: 1.3958 - acc: 0.5417\n",
            "Epoch 197/500\n",
            "26/26 [==============================] - 0s 506us/sample - loss: 1.3058 - acc: 0.7083\n",
            "Epoch 198/500\n",
            "26/26 [==============================] - 0s 651us/sample - loss: 1.5244 - acc: 0.5417\n",
            "Epoch 199/500\n",
            "26/26 [==============================] - 0s 513us/sample - loss: 1.3851 - acc: 0.5417\n",
            "Epoch 200/500\n",
            "26/26 [==============================] - 0s 559us/sample - loss: 1.4107 - acc: 0.5833\n",
            "Epoch 201/500\n",
            "26/26 [==============================] - 0s 629us/sample - loss: 1.3967 - acc: 0.6667\n",
            "Epoch 202/500\n",
            "26/26 [==============================] - 0s 656us/sample - loss: 1.3866 - acc: 0.5417\n",
            "Epoch 203/500\n",
            "26/26 [==============================] - 0s 556us/sample - loss: 1.3929 - acc: 0.5833\n",
            "Epoch 204/500\n",
            "26/26 [==============================] - 0s 627us/sample - loss: 1.4028 - acc: 0.6667\n",
            "Epoch 205/500\n",
            "26/26 [==============================] - 0s 508us/sample - loss: 1.3332 - acc: 0.7083\n",
            "Epoch 206/500\n",
            "26/26 [==============================] - 0s 633us/sample - loss: 1.3426 - acc: 0.5000\n",
            "Epoch 207/500\n",
            "26/26 [==============================] - 0s 498us/sample - loss: 1.3201 - acc: 0.6667\n",
            "Epoch 208/500\n",
            "26/26 [==============================] - 0s 521us/sample - loss: 1.5095 - acc: 0.4583\n",
            "Epoch 209/500\n",
            "26/26 [==============================] - 0s 556us/sample - loss: 1.2374 - acc: 0.6250\n",
            "Epoch 210/500\n",
            "26/26 [==============================] - 0s 512us/sample - loss: 1.2613 - acc: 0.6250\n",
            "Epoch 211/500\n",
            "26/26 [==============================] - 0s 461us/sample - loss: 1.2465 - acc: 0.6667\n",
            "Epoch 212/500\n",
            "26/26 [==============================] - 0s 601us/sample - loss: 1.2254 - acc: 0.6250\n",
            "Epoch 213/500\n",
            "26/26 [==============================] - 0s 472us/sample - loss: 1.3209 - acc: 0.5000\n",
            "Epoch 214/500\n",
            "26/26 [==============================] - 0s 589us/sample - loss: 1.3028 - acc: 0.5833\n",
            "Epoch 215/500\n",
            "26/26 [==============================] - 0s 578us/sample - loss: 1.2240 - acc: 0.6667\n",
            "Epoch 216/500\n",
            "26/26 [==============================] - 0s 816us/sample - loss: 1.0889 - acc: 0.7500\n",
            "Epoch 217/500\n",
            "26/26 [==============================] - 0s 522us/sample - loss: 1.3104 - acc: 0.6250\n",
            "Epoch 218/500\n",
            "26/26 [==============================] - 0s 669us/sample - loss: 1.2537 - acc: 0.7083\n",
            "Epoch 219/500\n",
            "26/26 [==============================] - 0s 427us/sample - loss: 1.3322 - acc: 0.5417\n",
            "Epoch 220/500\n",
            "26/26 [==============================] - 0s 623us/sample - loss: 1.2700 - acc: 0.6667\n",
            "Epoch 221/500\n",
            "26/26 [==============================] - 0s 550us/sample - loss: 1.2397 - acc: 0.6250\n",
            "Epoch 222/500\n",
            "26/26 [==============================] - 0s 547us/sample - loss: 1.2539 - acc: 0.7500\n",
            "Epoch 223/500\n",
            "26/26 [==============================] - 0s 526us/sample - loss: 1.1710 - acc: 0.6667\n",
            "Epoch 224/500\n",
            "26/26 [==============================] - 0s 465us/sample - loss: 1.3245 - acc: 0.6250\n",
            "Epoch 225/500\n",
            "26/26 [==============================] - 0s 678us/sample - loss: 1.2895 - acc: 0.6667\n",
            "Epoch 226/500\n",
            "26/26 [==============================] - 0s 544us/sample - loss: 1.3193 - acc: 0.5000\n",
            "Epoch 227/500\n",
            "26/26 [==============================] - 0s 485us/sample - loss: 1.1978 - acc: 0.6667\n",
            "Epoch 228/500\n",
            "26/26 [==============================] - 0s 512us/sample - loss: 1.1652 - acc: 0.6667\n",
            "Epoch 229/500\n",
            "26/26 [==============================] - 0s 525us/sample - loss: 1.2668 - acc: 0.6250\n",
            "Epoch 230/500\n",
            "26/26 [==============================] - 0s 508us/sample - loss: 1.2394 - acc: 0.7083\n",
            "Epoch 231/500\n",
            "26/26 [==============================] - 0s 524us/sample - loss: 1.1753 - acc: 0.6250\n",
            "Epoch 232/500\n",
            "26/26 [==============================] - 0s 474us/sample - loss: 1.1603 - acc: 0.6250\n",
            "Epoch 233/500\n",
            "26/26 [==============================] - 0s 446us/sample - loss: 1.0769 - acc: 0.7500\n",
            "Epoch 234/500\n",
            "26/26 [==============================] - 0s 510us/sample - loss: 1.2470 - acc: 0.5833\n",
            "Epoch 235/500\n",
            "26/26 [==============================] - 0s 486us/sample - loss: 1.2264 - acc: 0.6667\n",
            "Epoch 236/500\n",
            "26/26 [==============================] - 0s 505us/sample - loss: 1.1395 - acc: 0.6667\n",
            "Epoch 237/500\n",
            "26/26 [==============================] - 0s 612us/sample - loss: 1.1900 - acc: 0.6250\n",
            "Epoch 238/500\n",
            "26/26 [==============================] - 0s 622us/sample - loss: 1.2338 - acc: 0.5833\n",
            "Epoch 239/500\n",
            "26/26 [==============================] - 0s 532us/sample - loss: 1.2009 - acc: 0.6250\n",
            "Epoch 240/500\n",
            "26/26 [==============================] - 0s 509us/sample - loss: 1.2110 - acc: 0.6250\n",
            "Epoch 241/500\n",
            "26/26 [==============================] - 0s 587us/sample - loss: 1.2137 - acc: 0.5833\n",
            "Epoch 242/500\n",
            "26/26 [==============================] - 0s 513us/sample - loss: 1.2458 - acc: 0.6250\n",
            "Epoch 243/500\n",
            "26/26 [==============================] - 0s 489us/sample - loss: 1.1323 - acc: 0.7083\n",
            "Epoch 244/500\n",
            "26/26 [==============================] - 0s 517us/sample - loss: 1.1014 - acc: 0.7083\n",
            "Epoch 245/500\n",
            "26/26 [==============================] - 0s 592us/sample - loss: 1.1377 - acc: 0.6250\n",
            "Epoch 246/500\n",
            "26/26 [==============================] - 0s 594us/sample - loss: 1.1896 - acc: 0.7083\n",
            "Epoch 247/500\n",
            "26/26 [==============================] - 0s 680us/sample - loss: 1.1759 - acc: 0.6250\n",
            "Epoch 248/500\n",
            "26/26 [==============================] - 0s 595us/sample - loss: 1.1117 - acc: 0.6667\n",
            "Epoch 249/500\n",
            "26/26 [==============================] - 0s 502us/sample - loss: 1.1941 - acc: 0.5417\n",
            "Epoch 250/500\n",
            "26/26 [==============================] - 0s 630us/sample - loss: 1.1271 - acc: 0.7917\n",
            "Epoch 251/500\n",
            "26/26 [==============================] - 0s 831us/sample - loss: 1.0816 - acc: 0.6667\n",
            "Epoch 252/500\n",
            "26/26 [==============================] - 0s 552us/sample - loss: 1.1646 - acc: 0.6667\n",
            "Epoch 253/500\n",
            "26/26 [==============================] - 0s 588us/sample - loss: 1.2287 - acc: 0.6667\n",
            "Epoch 254/500\n",
            "26/26 [==============================] - 0s 512us/sample - loss: 1.1092 - acc: 0.5833\n",
            "Epoch 255/500\n",
            "26/26 [==============================] - 0s 541us/sample - loss: 1.1182 - acc: 0.7083\n",
            "Epoch 256/500\n",
            "26/26 [==============================] - 0s 536us/sample - loss: 1.0847 - acc: 0.7500\n",
            "Epoch 257/500\n",
            "26/26 [==============================] - 0s 567us/sample - loss: 1.1352 - acc: 0.6250\n",
            "Epoch 258/500\n",
            "26/26 [==============================] - 0s 617us/sample - loss: 1.1017 - acc: 0.7500\n",
            "Epoch 259/500\n",
            "26/26 [==============================] - 0s 551us/sample - loss: 0.9792 - acc: 0.7917\n",
            "Epoch 260/500\n",
            "26/26 [==============================] - 0s 519us/sample - loss: 1.1995 - acc: 0.7083\n",
            "Epoch 261/500\n",
            "26/26 [==============================] - 0s 703us/sample - loss: 1.0916 - acc: 0.7500\n",
            "Epoch 262/500\n",
            "26/26 [==============================] - 0s 527us/sample - loss: 1.1345 - acc: 0.6667\n",
            "Epoch 263/500\n",
            "26/26 [==============================] - 0s 577us/sample - loss: 1.0746 - acc: 0.7083\n",
            "Epoch 264/500\n",
            "26/26 [==============================] - 0s 471us/sample - loss: 1.1314 - acc: 0.6250\n",
            "Epoch 265/500\n",
            "26/26 [==============================] - 0s 490us/sample - loss: 1.1780 - acc: 0.6250\n",
            "Epoch 266/500\n",
            "26/26 [==============================] - 0s 479us/sample - loss: 1.0218 - acc: 0.7917\n",
            "Epoch 267/500\n",
            "26/26 [==============================] - 0s 556us/sample - loss: 1.2276 - acc: 0.5833\n",
            "Epoch 268/500\n",
            "26/26 [==============================] - 0s 481us/sample - loss: 1.0884 - acc: 0.7500\n",
            "Epoch 269/500\n",
            "26/26 [==============================] - 0s 516us/sample - loss: 1.1273 - acc: 0.7917\n",
            "Epoch 270/500\n",
            "26/26 [==============================] - 0s 504us/sample - loss: 1.0407 - acc: 0.7500\n",
            "Epoch 271/500\n",
            "26/26 [==============================] - 0s 435us/sample - loss: 1.1245 - acc: 0.5833\n",
            "Epoch 272/500\n",
            "26/26 [==============================] - 0s 539us/sample - loss: 1.1585 - acc: 0.5417\n",
            "Epoch 273/500\n",
            "26/26 [==============================] - 0s 565us/sample - loss: 1.0441 - acc: 0.8333\n",
            "Epoch 274/500\n",
            "26/26 [==============================] - 0s 492us/sample - loss: 1.0251 - acc: 0.7500\n",
            "Epoch 275/500\n",
            "26/26 [==============================] - 0s 542us/sample - loss: 1.0162 - acc: 0.8333\n",
            "Epoch 276/500\n",
            "26/26 [==============================] - 0s 527us/sample - loss: 1.1773 - acc: 0.6250\n",
            "Epoch 277/500\n",
            "26/26 [==============================] - 0s 595us/sample - loss: 1.0259 - acc: 0.7083\n",
            "Epoch 278/500\n",
            "26/26 [==============================] - 0s 490us/sample - loss: 1.0685 - acc: 0.7500\n",
            "Epoch 279/500\n",
            "26/26 [==============================] - 0s 945us/sample - loss: 0.9581 - acc: 0.7083\n",
            "Epoch 280/500\n",
            "26/26 [==============================] - 0s 509us/sample - loss: 1.0525 - acc: 0.7083\n",
            "Epoch 281/500\n",
            "26/26 [==============================] - 0s 521us/sample - loss: 1.1423 - acc: 0.6250\n",
            "Epoch 282/500\n",
            "26/26 [==============================] - 0s 431us/sample - loss: 1.0188 - acc: 0.7500\n",
            "Epoch 283/500\n",
            "26/26 [==============================] - 0s 579us/sample - loss: 1.0404 - acc: 0.7083\n",
            "Epoch 284/500\n",
            "26/26 [==============================] - 0s 522us/sample - loss: 1.0200 - acc: 0.7083\n",
            "Epoch 285/500\n",
            "26/26 [==============================] - 0s 548us/sample - loss: 1.0985 - acc: 0.6667\n",
            "Epoch 286/500\n",
            "26/26 [==============================] - 0s 576us/sample - loss: 1.0723 - acc: 0.6667\n",
            "Epoch 287/500\n",
            "26/26 [==============================] - 0s 542us/sample - loss: 0.9466 - acc: 0.7500\n",
            "Epoch 288/500\n",
            "26/26 [==============================] - 0s 476us/sample - loss: 1.0399 - acc: 0.6250\n",
            "Epoch 289/500\n",
            "26/26 [==============================] - 0s 495us/sample - loss: 1.1647 - acc: 0.5833\n",
            "Epoch 290/500\n",
            "26/26 [==============================] - 0s 571us/sample - loss: 1.0483 - acc: 0.6667\n",
            "Epoch 291/500\n",
            "26/26 [==============================] - 0s 473us/sample - loss: 1.0868 - acc: 0.5833\n",
            "Epoch 292/500\n",
            "26/26 [==============================] - 0s 580us/sample - loss: 0.9946 - acc: 0.7083\n",
            "Epoch 293/500\n",
            "26/26 [==============================] - 0s 609us/sample - loss: 0.8830 - acc: 0.7917\n",
            "Epoch 294/500\n",
            "26/26 [==============================] - 0s 745us/sample - loss: 1.1361 - acc: 0.6667\n",
            "Epoch 295/500\n",
            "26/26 [==============================] - 0s 806us/sample - loss: 1.0383 - acc: 0.7083\n",
            "Epoch 296/500\n",
            "26/26 [==============================] - 0s 777us/sample - loss: 0.9719 - acc: 0.7083\n",
            "Epoch 297/500\n",
            "26/26 [==============================] - 0s 523us/sample - loss: 1.0546 - acc: 0.7500\n",
            "Epoch 298/500\n",
            "26/26 [==============================] - 0s 518us/sample - loss: 1.0488 - acc: 0.7083\n",
            "Epoch 299/500\n",
            "26/26 [==============================] - 0s 664us/sample - loss: 1.1585 - acc: 0.6250\n",
            "Epoch 300/500\n",
            "26/26 [==============================] - 0s 674us/sample - loss: 1.0266 - acc: 0.7500\n",
            "Epoch 301/500\n",
            "26/26 [==============================] - 0s 700us/sample - loss: 0.9690 - acc: 0.6667\n",
            "Epoch 302/500\n",
            "26/26 [==============================] - 0s 561us/sample - loss: 1.0643 - acc: 0.7917\n",
            "Epoch 303/500\n",
            "26/26 [==============================] - 0s 612us/sample - loss: 0.9657 - acc: 0.7500\n",
            "Epoch 304/500\n",
            "26/26 [==============================] - 0s 515us/sample - loss: 1.0443 - acc: 0.6250\n",
            "Epoch 305/500\n",
            "26/26 [==============================] - 0s 463us/sample - loss: 1.0243 - acc: 0.7917\n",
            "Epoch 306/500\n",
            "26/26 [==============================] - 0s 550us/sample - loss: 0.9696 - acc: 0.7917\n",
            "Epoch 307/500\n",
            "26/26 [==============================] - 0s 584us/sample - loss: 1.0424 - acc: 0.5833\n",
            "Epoch 308/500\n",
            "26/26 [==============================] - 0s 545us/sample - loss: 1.1485 - acc: 0.5833\n",
            "Epoch 309/500\n",
            "26/26 [==============================] - 0s 465us/sample - loss: 0.9324 - acc: 0.7500\n",
            "Epoch 310/500\n",
            "26/26 [==============================] - 0s 591us/sample - loss: 0.9576 - acc: 0.8750\n",
            "Epoch 311/500\n",
            "26/26 [==============================] - 0s 587us/sample - loss: 0.9430 - acc: 0.7500\n",
            "Epoch 312/500\n",
            "26/26 [==============================] - 0s 544us/sample - loss: 0.9589 - acc: 0.7500\n",
            "Epoch 313/500\n",
            "26/26 [==============================] - 0s 602us/sample - loss: 0.8489 - acc: 0.8333\n",
            "Epoch 314/500\n",
            "26/26 [==============================] - 0s 506us/sample - loss: 0.9560 - acc: 0.7500\n",
            "Epoch 315/500\n",
            "26/26 [==============================] - 0s 565us/sample - loss: 0.9450 - acc: 0.7917\n",
            "Epoch 316/500\n",
            "26/26 [==============================] - 0s 538us/sample - loss: 0.8494 - acc: 0.7917\n",
            "Epoch 317/500\n",
            "26/26 [==============================] - 0s 551us/sample - loss: 0.9941 - acc: 0.7083\n",
            "Epoch 318/500\n",
            "26/26 [==============================] - 0s 529us/sample - loss: 1.0279 - acc: 0.7083\n",
            "Epoch 319/500\n",
            "26/26 [==============================] - 0s 627us/sample - loss: 0.8670 - acc: 0.7917\n",
            "Epoch 320/500\n",
            "26/26 [==============================] - 0s 499us/sample - loss: 0.9843 - acc: 0.6667\n",
            "Epoch 321/500\n",
            "26/26 [==============================] - 0s 553us/sample - loss: 0.9679 - acc: 0.7917\n",
            "Epoch 322/500\n",
            "26/26 [==============================] - 0s 585us/sample - loss: 0.9966 - acc: 0.7083\n",
            "Epoch 323/500\n",
            "26/26 [==============================] - 0s 538us/sample - loss: 0.9257 - acc: 0.7083\n",
            "Epoch 324/500\n",
            "26/26 [==============================] - 0s 455us/sample - loss: 0.9687 - acc: 0.7917\n",
            "Epoch 325/500\n",
            "26/26 [==============================] - 0s 519us/sample - loss: 1.0039 - acc: 0.6250\n",
            "Epoch 326/500\n",
            "26/26 [==============================] - 0s 550us/sample - loss: 0.8611 - acc: 0.8333\n",
            "Epoch 327/500\n",
            "26/26 [==============================] - 0s 571us/sample - loss: 1.0668 - acc: 0.5417\n",
            "Epoch 328/500\n",
            "26/26 [==============================] - 0s 463us/sample - loss: 0.8730 - acc: 0.7500\n",
            "Epoch 329/500\n",
            "26/26 [==============================] - 0s 528us/sample - loss: 0.9412 - acc: 0.7500\n",
            "Epoch 330/500\n",
            "26/26 [==============================] - 0s 466us/sample - loss: 0.8124 - acc: 0.7917\n",
            "Epoch 331/500\n",
            "26/26 [==============================] - 0s 502us/sample - loss: 0.9647 - acc: 0.7917\n",
            "Epoch 332/500\n",
            "26/26 [==============================] - 0s 478us/sample - loss: 0.9502 - acc: 0.7083\n",
            "Epoch 333/500\n",
            "26/26 [==============================] - 0s 512us/sample - loss: 0.8184 - acc: 0.7917\n",
            "Epoch 334/500\n",
            "26/26 [==============================] - 0s 467us/sample - loss: 0.9236 - acc: 0.8333\n",
            "Epoch 335/500\n",
            "26/26 [==============================] - 0s 451us/sample - loss: 0.8899 - acc: 0.7500\n",
            "Epoch 336/500\n",
            "26/26 [==============================] - 0s 512us/sample - loss: 0.9539 - acc: 0.7083\n",
            "Epoch 337/500\n",
            "26/26 [==============================] - 0s 456us/sample - loss: 0.9348 - acc: 0.7500\n",
            "Epoch 338/500\n",
            "26/26 [==============================] - 0s 463us/sample - loss: 0.9543 - acc: 0.6667\n",
            "Epoch 339/500\n",
            "26/26 [==============================] - 0s 595us/sample - loss: 0.8039 - acc: 0.7500\n",
            "Epoch 340/500\n",
            "26/26 [==============================] - 0s 605us/sample - loss: 0.9213 - acc: 0.7500\n",
            "Epoch 341/500\n",
            "26/26 [==============================] - 0s 603us/sample - loss: 0.8735 - acc: 0.7500\n",
            "Epoch 342/500\n",
            "26/26 [==============================] - 0s 513us/sample - loss: 0.9416 - acc: 0.7083\n",
            "Epoch 343/500\n",
            "26/26 [==============================] - 0s 495us/sample - loss: 0.9711 - acc: 0.7500\n",
            "Epoch 344/500\n",
            "26/26 [==============================] - 0s 836us/sample - loss: 0.8854 - acc: 0.7917\n",
            "Epoch 345/500\n",
            "26/26 [==============================] - 0s 607us/sample - loss: 0.9013 - acc: 0.7083\n",
            "Epoch 346/500\n",
            "26/26 [==============================] - 0s 523us/sample - loss: 0.9433 - acc: 0.7917\n",
            "Epoch 347/500\n",
            "26/26 [==============================] - 0s 466us/sample - loss: 0.9012 - acc: 0.7500\n",
            "Epoch 348/500\n",
            "26/26 [==============================] - 0s 479us/sample - loss: 0.9056 - acc: 0.6667\n",
            "Epoch 349/500\n",
            "26/26 [==============================] - 0s 544us/sample - loss: 0.8895 - acc: 0.6667\n",
            "Epoch 350/500\n",
            "26/26 [==============================] - 0s 504us/sample - loss: 0.8133 - acc: 0.7917\n",
            "Epoch 351/500\n",
            "26/26 [==============================] - 0s 706us/sample - loss: 0.9110 - acc: 0.9167\n",
            "Epoch 352/500\n",
            "26/26 [==============================] - 0s 520us/sample - loss: 0.9489 - acc: 0.6667\n",
            "Epoch 353/500\n",
            "26/26 [==============================] - 0s 490us/sample - loss: 0.8445 - acc: 0.8333\n",
            "Epoch 354/500\n",
            "26/26 [==============================] - 0s 480us/sample - loss: 0.9262 - acc: 0.6667\n",
            "Epoch 355/500\n",
            "26/26 [==============================] - 0s 657us/sample - loss: 0.8251 - acc: 0.7917\n",
            "Epoch 356/500\n",
            "26/26 [==============================] - 0s 511us/sample - loss: 0.9086 - acc: 0.7500\n",
            "Epoch 357/500\n",
            "26/26 [==============================] - 0s 572us/sample - loss: 0.7569 - acc: 0.8333\n",
            "Epoch 358/500\n",
            "26/26 [==============================] - 0s 513us/sample - loss: 0.9223 - acc: 0.7083\n",
            "Epoch 359/500\n",
            "26/26 [==============================] - 0s 487us/sample - loss: 0.8482 - acc: 0.7500\n",
            "Epoch 360/500\n",
            "26/26 [==============================] - 0s 488us/sample - loss: 0.8537 - acc: 0.7917\n",
            "Epoch 361/500\n",
            "26/26 [==============================] - 0s 504us/sample - loss: 0.8497 - acc: 0.7083\n",
            "Epoch 362/500\n",
            "26/26 [==============================] - 0s 614us/sample - loss: 0.8407 - acc: 0.7917\n",
            "Epoch 363/500\n",
            "26/26 [==============================] - 0s 469us/sample - loss: 0.8934 - acc: 0.8333\n",
            "Epoch 364/500\n",
            "26/26 [==============================] - 0s 588us/sample - loss: 0.8018 - acc: 0.7500\n",
            "Epoch 365/500\n",
            "26/26 [==============================] - 0s 601us/sample - loss: 0.8642 - acc: 0.7917\n",
            "Epoch 366/500\n",
            "26/26 [==============================] - 0s 510us/sample - loss: 0.8170 - acc: 0.7917\n",
            "Epoch 367/500\n",
            "26/26 [==============================] - 0s 495us/sample - loss: 0.8568 - acc: 0.7083\n",
            "Epoch 368/500\n",
            "26/26 [==============================] - 0s 536us/sample - loss: 0.8526 - acc: 0.7500\n",
            "Epoch 369/500\n",
            "26/26 [==============================] - 0s 471us/sample - loss: 0.7969 - acc: 0.7500\n",
            "Epoch 370/500\n",
            "26/26 [==============================] - 0s 490us/sample - loss: 0.8840 - acc: 0.7500\n",
            "Epoch 371/500\n",
            "26/26 [==============================] - 0s 524us/sample - loss: 0.6628 - acc: 0.8750\n",
            "Epoch 372/500\n",
            "26/26 [==============================] - 0s 593us/sample - loss: 0.8031 - acc: 0.7917\n",
            "Epoch 373/500\n",
            "26/26 [==============================] - 0s 602us/sample - loss: 0.8282 - acc: 0.7083\n",
            "Epoch 374/500\n",
            "26/26 [==============================] - 0s 486us/sample - loss: 0.7918 - acc: 0.7500\n",
            "Epoch 375/500\n",
            "26/26 [==============================] - 0s 450us/sample - loss: 0.7939 - acc: 0.8333\n",
            "Epoch 376/500\n",
            "26/26 [==============================] - 0s 499us/sample - loss: 0.8815 - acc: 0.7500\n",
            "Epoch 377/500\n",
            "26/26 [==============================] - 0s 516us/sample - loss: 0.7504 - acc: 0.8333\n",
            "Epoch 378/500\n",
            "26/26 [==============================] - 0s 484us/sample - loss: 0.7920 - acc: 0.7917\n",
            "Epoch 379/500\n",
            "26/26 [==============================] - 0s 480us/sample - loss: 0.8069 - acc: 0.8333\n",
            "Epoch 380/500\n",
            "26/26 [==============================] - 0s 500us/sample - loss: 0.7880 - acc: 0.8750\n",
            "Epoch 381/500\n",
            "26/26 [==============================] - 0s 498us/sample - loss: 0.8559 - acc: 0.6667\n",
            "Epoch 382/500\n",
            "26/26 [==============================] - 0s 648us/sample - loss: 0.7769 - acc: 0.7917\n",
            "Epoch 383/500\n",
            "26/26 [==============================] - 0s 533us/sample - loss: 0.9152 - acc: 0.6667\n",
            "Epoch 384/500\n",
            "26/26 [==============================] - 0s 576us/sample - loss: 0.8159 - acc: 0.8333\n",
            "Epoch 385/500\n",
            "26/26 [==============================] - 0s 440us/sample - loss: 0.8128 - acc: 0.7500\n",
            "Epoch 386/500\n",
            "26/26 [==============================] - 0s 731us/sample - loss: 0.7594 - acc: 0.8333\n",
            "Epoch 387/500\n",
            "26/26 [==============================] - 0s 589us/sample - loss: 0.8262 - acc: 0.7917\n",
            "Epoch 388/500\n",
            "26/26 [==============================] - 0s 569us/sample - loss: 0.7574 - acc: 0.7917\n",
            "Epoch 389/500\n",
            "26/26 [==============================] - 0s 623us/sample - loss: 0.7933 - acc: 0.7917\n",
            "Epoch 390/500\n",
            "26/26 [==============================] - 0s 609us/sample - loss: 0.8588 - acc: 0.7500\n",
            "Epoch 391/500\n",
            "26/26 [==============================] - 0s 541us/sample - loss: 0.7113 - acc: 0.8333\n",
            "Epoch 392/500\n",
            "26/26 [==============================] - 0s 537us/sample - loss: 0.7757 - acc: 0.8333\n",
            "Epoch 393/500\n",
            "26/26 [==============================] - 0s 546us/sample - loss: 0.8888 - acc: 0.7083\n",
            "Epoch 394/500\n",
            "26/26 [==============================] - 0s 643us/sample - loss: 0.7030 - acc: 0.8750\n",
            "Epoch 395/500\n",
            "26/26 [==============================] - 0s 536us/sample - loss: 0.6945 - acc: 0.8750\n",
            "Epoch 396/500\n",
            "26/26 [==============================] - 0s 479us/sample - loss: 0.7463 - acc: 0.7500\n",
            "Epoch 397/500\n",
            "26/26 [==============================] - 0s 445us/sample - loss: 0.6968 - acc: 0.8333\n",
            "Epoch 398/500\n",
            "26/26 [==============================] - 0s 458us/sample - loss: 0.7895 - acc: 0.7500\n",
            "Epoch 399/500\n",
            "26/26 [==============================] - 0s 537us/sample - loss: 0.7120 - acc: 0.7917\n",
            "Epoch 400/500\n",
            "26/26 [==============================] - 0s 681us/sample - loss: 0.7083 - acc: 0.8333\n",
            "Epoch 401/500\n",
            "26/26 [==============================] - 0s 560us/sample - loss: 0.8240 - acc: 0.7083\n",
            "Epoch 402/500\n",
            "26/26 [==============================] - 0s 436us/sample - loss: 0.7361 - acc: 0.7500\n",
            "Epoch 403/500\n",
            "26/26 [==============================] - 0s 472us/sample - loss: 0.6914 - acc: 0.7500\n",
            "Epoch 404/500\n",
            "26/26 [==============================] - 0s 448us/sample - loss: 0.6373 - acc: 0.8750\n",
            "Epoch 405/500\n",
            "26/26 [==============================] - 0s 667us/sample - loss: 0.7489 - acc: 0.7500\n",
            "Epoch 406/500\n",
            "26/26 [==============================] - 0s 543us/sample - loss: 0.6996 - acc: 0.8333\n",
            "Epoch 407/500\n",
            "26/26 [==============================] - 0s 582us/sample - loss: 0.6265 - acc: 0.8333\n",
            "Epoch 408/500\n",
            "26/26 [==============================] - 0s 505us/sample - loss: 0.7186 - acc: 0.7500\n",
            "Epoch 409/500\n",
            "26/26 [==============================] - 0s 572us/sample - loss: 0.6978 - acc: 0.8333\n",
            "Epoch 410/500\n",
            "26/26 [==============================] - 0s 573us/sample - loss: 0.7239 - acc: 0.8333\n",
            "Epoch 411/500\n",
            "26/26 [==============================] - 0s 534us/sample - loss: 0.6564 - acc: 0.8750\n",
            "Epoch 412/500\n",
            "26/26 [==============================] - 0s 568us/sample - loss: 0.7409 - acc: 0.7917\n",
            "Epoch 413/500\n",
            "26/26 [==============================] - 0s 473us/sample - loss: 0.7397 - acc: 0.8750\n",
            "Epoch 414/500\n",
            "26/26 [==============================] - 0s 470us/sample - loss: 0.6841 - acc: 0.8750\n",
            "Epoch 415/500\n",
            "26/26 [==============================] - 0s 427us/sample - loss: 0.7593 - acc: 0.7917\n",
            "Epoch 416/500\n",
            "26/26 [==============================] - 0s 513us/sample - loss: 0.7450 - acc: 0.8750\n",
            "Epoch 417/500\n",
            "26/26 [==============================] - 0s 686us/sample - loss: 0.7036 - acc: 0.7500\n",
            "Epoch 418/500\n",
            "26/26 [==============================] - 0s 826us/sample - loss: 0.5875 - acc: 0.9167\n",
            "Epoch 419/500\n",
            "26/26 [==============================] - 0s 528us/sample - loss: 0.7123 - acc: 0.8333\n",
            "Epoch 420/500\n",
            "26/26 [==============================] - 0s 549us/sample - loss: 0.7315 - acc: 0.7917\n",
            "Epoch 421/500\n",
            "26/26 [==============================] - 0s 475us/sample - loss: 0.7599 - acc: 0.7917\n",
            "Epoch 422/500\n",
            "26/26 [==============================] - 0s 534us/sample - loss: 0.7088 - acc: 0.7917\n",
            "Epoch 423/500\n",
            "26/26 [==============================] - 0s 463us/sample - loss: 0.6203 - acc: 0.8750\n",
            "Epoch 424/500\n",
            "26/26 [==============================] - 0s 505us/sample - loss: 0.6891 - acc: 0.8333\n",
            "Epoch 425/500\n",
            "26/26 [==============================] - 0s 546us/sample - loss: 0.7422 - acc: 0.7500\n",
            "Epoch 426/500\n",
            "26/26 [==============================] - 0s 551us/sample - loss: 0.7068 - acc: 0.8333\n",
            "Epoch 427/500\n",
            "26/26 [==============================] - 0s 425us/sample - loss: 0.7210 - acc: 0.8750\n",
            "Epoch 428/500\n",
            "26/26 [==============================] - 0s 542us/sample - loss: 0.8342 - acc: 0.6667\n",
            "Epoch 429/500\n",
            "26/26 [==============================] - 0s 503us/sample - loss: 0.6736 - acc: 0.8750\n",
            "Epoch 430/500\n",
            "26/26 [==============================] - 0s 504us/sample - loss: 0.6922 - acc: 0.8750\n",
            "Epoch 431/500\n",
            "26/26 [==============================] - 0s 460us/sample - loss: 0.7024 - acc: 0.8333\n",
            "Epoch 432/500\n",
            "26/26 [==============================] - 0s 617us/sample - loss: 0.6515 - acc: 0.7917\n",
            "Epoch 433/500\n",
            "26/26 [==============================] - 0s 596us/sample - loss: 0.6638 - acc: 0.8750\n",
            "Epoch 434/500\n",
            "26/26 [==============================] - 0s 557us/sample - loss: 0.6829 - acc: 0.8333\n",
            "Epoch 435/500\n",
            "26/26 [==============================] - 0s 515us/sample - loss: 0.5940 - acc: 0.8750\n",
            "Epoch 436/500\n",
            "26/26 [==============================] - 0s 601us/sample - loss: 0.6232 - acc: 0.8750\n",
            "Epoch 437/500\n",
            "26/26 [==============================] - 0s 523us/sample - loss: 0.6609 - acc: 0.8750\n",
            "Epoch 438/500\n",
            "26/26 [==============================] - 0s 470us/sample - loss: 0.6635 - acc: 0.7917\n",
            "Epoch 439/500\n",
            "26/26 [==============================] - 0s 463us/sample - loss: 0.7112 - acc: 0.7500\n",
            "Epoch 440/500\n",
            "26/26 [==============================] - 0s 604us/sample - loss: 0.7427 - acc: 0.7917\n",
            "Epoch 441/500\n",
            "26/26 [==============================] - 0s 584us/sample - loss: 0.6103 - acc: 0.8333\n",
            "Epoch 442/500\n",
            "26/26 [==============================] - 0s 578us/sample - loss: 0.6730 - acc: 0.8750\n",
            "Epoch 443/500\n",
            "26/26 [==============================] - 0s 734us/sample - loss: 0.6910 - acc: 0.8333\n",
            "Epoch 444/500\n",
            "26/26 [==============================] - 0s 490us/sample - loss: 0.7183 - acc: 0.7500\n",
            "Epoch 445/500\n",
            "26/26 [==============================] - 0s 591us/sample - loss: 0.6623 - acc: 0.8750\n",
            "Epoch 446/500\n",
            "26/26 [==============================] - 0s 556us/sample - loss: 0.7497 - acc: 0.8750\n",
            "Epoch 447/500\n",
            "26/26 [==============================] - 0s 507us/sample - loss: 0.6230 - acc: 0.9167\n",
            "Epoch 448/500\n",
            "26/26 [==============================] - 0s 544us/sample - loss: 0.6292 - acc: 0.8750\n",
            "Epoch 449/500\n",
            "26/26 [==============================] - 0s 472us/sample - loss: 0.5790 - acc: 0.9167\n",
            "Epoch 450/500\n",
            "26/26 [==============================] - 0s 501us/sample - loss: 0.6372 - acc: 0.8333\n",
            "Epoch 451/500\n",
            "26/26 [==============================] - 0s 504us/sample - loss: 0.6106 - acc: 0.9167\n",
            "Epoch 452/500\n",
            "26/26 [==============================] - 0s 526us/sample - loss: 0.7018 - acc: 0.7917\n",
            "Epoch 453/500\n",
            "26/26 [==============================] - 0s 436us/sample - loss: 0.6088 - acc: 0.9167\n",
            "Epoch 454/500\n",
            "26/26 [==============================] - 0s 461us/sample - loss: 0.7220 - acc: 0.8333\n",
            "Epoch 455/500\n",
            "26/26 [==============================] - 0s 495us/sample - loss: 0.6475 - acc: 0.7917\n",
            "Epoch 456/500\n",
            "26/26 [==============================] - 0s 485us/sample - loss: 0.6447 - acc: 0.9167\n",
            "Epoch 457/500\n",
            "26/26 [==============================] - 0s 419us/sample - loss: 0.6215 - acc: 0.8750\n",
            "Epoch 458/500\n",
            "26/26 [==============================] - 0s 431us/sample - loss: 0.6939 - acc: 0.8750\n",
            "Epoch 459/500\n",
            "26/26 [==============================] - 0s 536us/sample - loss: 0.6669 - acc: 0.8333\n",
            "Epoch 460/500\n",
            "26/26 [==============================] - 0s 468us/sample - loss: 0.5979 - acc: 0.8750\n",
            "Epoch 461/500\n",
            "26/26 [==============================] - 0s 482us/sample - loss: 0.6285 - acc: 0.8750\n",
            "Epoch 462/500\n",
            "26/26 [==============================] - 0s 500us/sample - loss: 0.5532 - acc: 0.9167\n",
            "Epoch 463/500\n",
            "26/26 [==============================] - 0s 486us/sample - loss: 0.6920 - acc: 0.7500\n",
            "Epoch 464/500\n",
            "26/26 [==============================] - 0s 507us/sample - loss: 0.5408 - acc: 0.9167\n",
            "Epoch 465/500\n",
            "26/26 [==============================] - 0s 447us/sample - loss: 0.6290 - acc: 0.8750\n",
            "Epoch 466/500\n",
            "26/26 [==============================] - 0s 421us/sample - loss: 0.5459 - acc: 0.9167\n",
            "Epoch 467/500\n",
            "26/26 [==============================] - 0s 472us/sample - loss: 0.5847 - acc: 1.0000\n",
            "Epoch 468/500\n",
            "26/26 [==============================] - 0s 414us/sample - loss: 0.6659 - acc: 0.8333\n",
            "Epoch 469/500\n",
            "26/26 [==============================] - 0s 442us/sample - loss: 0.6723 - acc: 0.7917\n",
            "Epoch 470/500\n",
            "26/26 [==============================] - 0s 514us/sample - loss: 0.6616 - acc: 0.7917\n",
            "Epoch 471/500\n",
            "26/26 [==============================] - 0s 477us/sample - loss: 0.5705 - acc: 0.8333\n",
            "Epoch 472/500\n",
            "26/26 [==============================] - 0s 466us/sample - loss: 0.5998 - acc: 0.8750\n",
            "Epoch 473/500\n",
            "26/26 [==============================] - 0s 501us/sample - loss: 0.5483 - acc: 0.9167\n",
            "Epoch 474/500\n",
            "26/26 [==============================] - 0s 465us/sample - loss: 0.5559 - acc: 0.9583\n",
            "Epoch 475/500\n",
            "26/26 [==============================] - 0s 503us/sample - loss: 0.5731 - acc: 0.8333\n",
            "Epoch 476/500\n",
            "26/26 [==============================] - 0s 462us/sample - loss: 0.5367 - acc: 0.9583\n",
            "Epoch 477/500\n",
            "26/26 [==============================] - 0s 456us/sample - loss: 0.5776 - acc: 0.8750\n",
            "Epoch 478/500\n",
            "26/26 [==============================] - 0s 520us/sample - loss: 0.5041 - acc: 0.9167\n",
            "Epoch 479/500\n",
            "26/26 [==============================] - 0s 598us/sample - loss: 0.5053 - acc: 0.9583\n",
            "Epoch 480/500\n",
            "26/26 [==============================] - 0s 525us/sample - loss: 0.5234 - acc: 0.9583\n",
            "Epoch 481/500\n",
            "26/26 [==============================] - 0s 450us/sample - loss: 0.5317 - acc: 0.9167\n",
            "Epoch 482/500\n",
            "26/26 [==============================] - 0s 431us/sample - loss: 0.4739 - acc: 0.9583\n",
            "Epoch 483/500\n",
            "26/26 [==============================] - 0s 443us/sample - loss: 0.4805 - acc: 0.9167\n",
            "Epoch 484/500\n",
            "26/26 [==============================] - 0s 476us/sample - loss: 0.5273 - acc: 0.9167\n",
            "Epoch 485/500\n",
            "26/26 [==============================] - 0s 440us/sample - loss: 0.6039 - acc: 0.8750\n",
            "Epoch 486/500\n",
            "26/26 [==============================] - 0s 610us/sample - loss: 0.5894 - acc: 0.7917\n",
            "Epoch 487/500\n",
            "26/26 [==============================] - 0s 638us/sample - loss: 0.5348 - acc: 0.9167\n",
            "Epoch 488/500\n",
            "26/26 [==============================] - 0s 450us/sample - loss: 0.5117 - acc: 0.9583\n",
            "Epoch 489/500\n",
            "26/26 [==============================] - 0s 537us/sample - loss: 0.4791 - acc: 0.9583\n",
            "Epoch 490/500\n",
            "26/26 [==============================] - 0s 505us/sample - loss: 0.4571 - acc: 0.9167\n",
            "Epoch 491/500\n",
            "26/26 [==============================] - 0s 746us/sample - loss: 0.5856 - acc: 0.8750\n",
            "Epoch 492/500\n",
            "26/26 [==============================] - 0s 674us/sample - loss: 0.5215 - acc: 0.8333\n",
            "Epoch 493/500\n",
            "26/26 [==============================] - 0s 560us/sample - loss: 0.5200 - acc: 0.8750\n",
            "Epoch 494/500\n",
            "26/26 [==============================] - 0s 444us/sample - loss: 0.5039 - acc: 0.9167\n",
            "Epoch 495/500\n",
            "26/26 [==============================] - 0s 592us/sample - loss: 0.5429 - acc: 0.9167\n",
            "Epoch 496/500\n",
            "26/26 [==============================] - 0s 614us/sample - loss: 0.4969 - acc: 0.9167\n",
            "Epoch 497/500\n",
            "26/26 [==============================] - 0s 462us/sample - loss: 0.5603 - acc: 0.8333\n",
            "Epoch 498/500\n",
            "26/26 [==============================] - 0s 464us/sample - loss: 0.4769 - acc: 0.8750\n",
            "Epoch 499/500\n",
            "26/26 [==============================] - 0s 547us/sample - loss: 0.5936 - acc: 0.9167\n",
            "Epoch 500/500\n",
            "26/26 [==============================] - 0s 478us/sample - loss: 0.4834 - acc: 0.8750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa3d1dfd4a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzZe48vENjUN",
        "colab_type": "code",
        "outputId": "8073a9e8-fcc4-4e80-8cf4-d0d2b093fcc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        }
      },
      "source": [
        "# Create the plot\n",
        "plt.plot(tpu_model.history.history['acc'], 'r', tpu_model.history.history['loss'], 'b')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation score')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFYCAYAAAB6RnQAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueawbr1eGsVL",
        "colab_type": "code",
        "outputId": "97b02673-233b-44f9-e73d-66191474c898",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "cpu_model = tpu_model.sync_to_cpu()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4XK5eh-VSb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cpu_model.save_weights('Deep_Writing_with_sentence-word_prediction-tpu.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oml2ac7Vjds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cpu_model.load_weights('Deep_Writing_with_sentence-word_prediction-tpu.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npQJ92OeXPp-",
        "colab_type": "code",
        "outputId": "57a22a8b-87ff-41cd-cc08-8ba0a136f852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "X[9]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.        ,  0.2       ,  0.28867513,  0.36115756,  0.42640143,\n",
              "        0.48795004,  0.54772256,  0.60697698,  0.66666667,  0.72760688,\n",
              "       -1.26491106, -1.16774842, -1.08012345, -1.        , -0.9258201 ,\n",
              "       -0.85634884, -0.79056942, -0.72760688, -0.66666667, -0.60697698,\n",
              "       -0.54772256, -0.48795004, -0.42640143, -0.36115756, -0.28867513,\n",
              "       -0.2       ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2FfpFmij3oC",
        "colab_type": "code",
        "outputId": "30f33393-024c-4dbb-adc2-2c0c6d020e12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_lstm[0:10].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 26, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIE3gxpeGtLr",
        "colab_type": "code",
        "outputId": "38798967-9ac7-416f-a5c3-9aff1f4937b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "pred = cpu_model.predict(X_lstm[0:])\n",
        "print(pred.shape)\n",
        "line = []\n",
        "for i in range(len(pred)):\n",
        "  line.append(tokenizer.index_word[np.argmax(pred[i])])\n",
        "  \n",
        "' '.join(line)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(26, 24)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'that of any dont of my adventures with mr sherlock holmes opened quite so or or so dramatically as that which i associate with the thre'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    }
  ]
}